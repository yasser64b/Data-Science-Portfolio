{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Fashion MNIST dataset\n",
    "\n",
    "\n",
    "------------\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "**Project:  to build an image classifier with Keras and Convolutional Neural Networks for the Fashion MNIST dataset. This data set includes 10 labels of different clothing types with 28 by 28 *grayscale* images. There is a training set of 60,000 images and 10,000 test images.**\n",
    "\n",
    "    Label\tDescription\n",
    "    0\t    T-shirt/top\n",
    "    1\t    Trouser\n",
    "    2\t    Pullover\n",
    "    3\t    Dress\n",
    "    4\t    Coat\n",
    "    5\t    Sandal\n",
    "    6\t    Shirt\n",
    "    7\t    Sneaker\n",
    "    8\t    Bag\n",
    "    9\t    Ankle boot\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 57s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 4s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  85, 188, 146,  79,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 140, 202, 199, 255, 144,   0,   0,   0,   0,  11, 135, 157,\n",
       "          5,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0,\n",
       "          0, 200, 187, 200, 191, 255,  51,   0,   0,  16, 208, 227, 236,\n",
       "         63,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,\n",
       "         18, 233, 193, 206, 186, 219, 255, 171, 140, 255, 221, 203, 217,\n",
       "         43,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        107, 217, 195, 203, 204, 209, 216, 244, 255, 213, 207, 218, 228,\n",
       "         72,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        231, 216, 209, 204, 205, 217, 218, 214, 213, 201, 210, 215, 233,\n",
       "        128,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,  33,\n",
       "        255, 206, 214, 204, 213, 218, 213, 217, 222, 196, 201, 205, 231,\n",
       "        185,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   9,   2,   0, 159,\n",
       "        234, 193, 209, 206, 215, 218, 217, 221, 210, 201, 205, 214, 219,\n",
       "        249,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,  77, 255,\n",
       "        219, 207, 204, 205, 213, 213, 215, 213, 203, 211, 217, 217, 202,\n",
       "        255,  71],\n",
       "       [  0,   0,   1,   2,   3,   3,   1,   0,   0,   0, 121, 245, 214,\n",
       "        219, 210, 200, 205, 215, 215, 219, 214, 204, 208, 213, 214, 201,\n",
       "        246, 118],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  78, 216, 255, 208, 205,\n",
       "        214, 197, 202, 214, 211, 210, 213, 211, 208, 214, 204, 208, 207,\n",
       "        237, 136],\n",
       "       [  0,   0,   0,   0,  19,  87, 135, 211, 255, 217, 202, 206, 214,\n",
       "        209, 198, 202, 214, 214, 211, 213, 200, 207, 212, 201, 198, 203,\n",
       "        243, 130],\n",
       "       [  0,  64, 190, 219, 241, 214, 227, 216, 194, 193, 199, 201, 201,\n",
       "        213, 204, 198, 201, 205, 208, 202, 202, 205, 196, 198, 202, 201,\n",
       "        255,  73],\n",
       "       [ 23, 214, 209, 198, 198, 195, 200, 194, 212, 201, 201, 203, 204,\n",
       "        211, 204, 199, 199, 195, 194, 181, 187, 212, 208, 201, 212, 219,\n",
       "        245,  11],\n",
       "       [129, 220, 200, 207, 206, 204, 191, 202, 209, 212, 211, 207, 204,\n",
       "        202, 198, 206, 209, 198, 204, 222, 246, 223, 197, 179, 165, 163,\n",
       "        179,   0],\n",
       "       [125, 232, 211, 205, 213, 212, 215, 216, 214, 207, 200, 197, 200,\n",
       "        197, 205, 204, 213, 226, 240, 176,  91, 163, 164, 159, 162, 173,\n",
       "        198,   0],\n",
       "       [  0, 146, 212, 229, 215, 213, 203, 198, 206, 203, 202, 202, 197,\n",
       "        196, 208, 227, 225, 112,   0,   0,   0, 185, 160, 161, 155, 167,\n",
       "        204,   0],\n",
       "       [  0,   0,   5, 117, 211, 237, 255, 244, 231, 225, 216, 220, 228,\n",
       "        255, 245, 122,   0,   0,   0,   0,   0, 231, 214, 212, 221, 201,\n",
       "        228,   6],\n",
       "       [  0,   2,   0,   0,   0,   0,  66, 116, 160, 191, 207, 207, 200,\n",
       "        120,   0,   0,   0,   0,   2,   0,   0,  95,  85,  79,  67,  51,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1837584ca88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAASBUlEQVR4nO3df2yd1X0G8Ofxvf4VOwk2JsGEkAQUKJRBAC8UUmVslCygTYFVIIIEmUgb/iilaG0FaqWVf9ahbS2bpo4pNBlhpUGtWkamRaVpypSxlYCDUpIQIBCS4MSxkyYkdpw49vV3f/imcsHn+5r7673NeT6Sde379bn3+Po+fq/vec85NDOIyNmvJu0OiEhlKOwikVDYRSKhsItEQmEXiUS2kndWx3prQFMl71IkKqdwAqdtkOPVigo7ycUA/glABsD3zexx7/sb0ITreXMxdykijs22MVgr+GU8yQyA7wG4FcAVAJaSvKLQ2xOR8irmf/b5AN41s91mdhrAcwCWlKZbIlJqxYR9BoAPxnzdlb/ud5BcQbKTZOcQBou4OxEpRjFhH+9NgI+de2tmK82sw8w6alFfxN2JSDGKCXsXgJljvr4QwIHiuiMi5VJM2F8DMJfkHJJ1AO4GsK403RKRUit46M3Mhkk+COBFjA69rTazHSXrmYiUVFHj7Ga2HsD6EvVFRMpIp8uKREJhF4mEwi4SCYVdJBIKu0gkFHaRSCjsIpFQ2EUiobCLREJhF4mEwi4SCYVdJBIKu0gkFHaRSCjsIpFQ2EUiobCLREJhF4mEwi4SCYVdJBIKu0gkFHaRSCjsIpFQ2EUiobCLREJhF4mEwi4SCYVdJBIKu0gkitrFVc5+h1fc4NbnLnvbrb+6a06w1vbfdW7blqd/5dblkykq7CT3AOgDkAMwbGYdpeiUiJReKY7sf2xmh0twOyJSRvqfXSQSxYbdAPyc5BaSK8b7BpIrSHaS7BzCYJF3JyKFKvZl/AIzO0ByGoANJN8ys01jv8HMVgJYCQBT2GpF3p+IFKioI7uZHchf9gJ4HsD8UnRKREqv4LCTbCI5+cznABYB2F6qjolIaRXzMn46gOdJnrmdH5rZz0rSK6kaRzqG3fqsSUfc+vl/cDxY+8dFnW7bOQu/4NYvvd9vX06Zc6a69Z3fvsyt17edDNZm3/uO29YGC3vvq+Cwm9luAFcX2l5EKktDbyKRUNhFIqGwi0RCYReJhMIuEglNcT0LMBv+NdqwP3SW5C+u2+LW3z9xrluf2Xg0WLtv70L/thd/363f/CfL3Xr2l37fPZnp09z6ZzfsdesPTXrFrZ+fCQ9JPnTrl922jf/xqlsP0ZFdJBIKu0gkFHaRSCjsIpFQ2EUiobCLREJhF4mExtnPAjZS+AJA2fbz3fqdLf/l1p8a+iO3PiV7KljbO9Dqtn3meJtb3/iDVW79hl9/Plg7+IF/3+//2VNu/bm+Fre+qc+f4npJQ2+w1tBTnuXbdGQXiYTCLhIJhV0kEgq7SCQUdpFIKOwikVDYRSKhcfazwUiu4Kbv33+xW98xOMOtZ2v8+x4cCT/FPjW5x23bPeSPZa885m/5/ONPrwnWLry62W37z0dnufVjuUa3fmnjQbd+QTY8z79vtn/bUwrcyVpHdpFIKOwikVDYRSKhsItEQmEXiYTCLhIJhV0kEhpnj9y/Lv8Xt/7W4AVu/eLGw269L9cQrGU44rZty/a59aT2L/RfHqyNmH+c2zfoz3efVhde9x0ATo3UuvUpNeF5/r3z3aaYstavhyQe2UmuJtlLcvuY61pJbiC5K3/pn/0gIqmbyMv4pwEs/sh1jwLYaGZzAWzMfy0iVSwx7Ga2CcCRj1y9BMCZcxHXALi9xP0SkRIr9A266WbWDQD5y+DGWCRXkOwk2TmE8qytJSLJyv5uvJmtNLMOM+uoRX25705EAgoNew/JdgDIX4aXyhSRqlBo2NcBWJb/fBmAF0rTHREpl8RxdpJrAdwEoI1kF4BvAXgcwI9ILgewD8Cd5exk9Ei/buF142uu/JTbdGHDVrf+Ut85br2t1h8L98bZ27L9btukcfS+hDnlk2rC7xFNzp502+4caHfrvaenuPX+TPjnBoArGvYHa1df957b9oRbDUsMu5ktDZRuLvA+RSQFOl1WJBIKu0gkFHaRSCjsIpFQ2EUioSmuVaBm8mS3PnJiwL8BCy/nvPcx/1f86uCQW9930p/q2VDjt69luG+1HHbbJvGG1gCgyanvPe1vB92U8W97Uua0W59W60+B3ePc/79dvM5texducOshOrKLREJhF4mEwi4SCYVdJBIKu0gkFHaRSCjsIpHQOHslJExRHenzp4km+fC+8Ljrmzc+6bZ95rg/lXPOpMKXigb8aapD5j/9hnJ+PWmc/tBweBrq0aEmt2173TG3PjWTcO5Dgh0nLwzW7puS8Jjf/ZlgbeTFV4I1HdlFIqGwi0RCYReJhMIuEgmFXSQSCrtIJBR2kUj8fo2ze+PV9P9usSZhOeYElgvPy/aWcp5QPcHux/35y5vu+ftg7XsfhrctBoDJNf6SyvUJ89WPDk1y683Z8Lzwcs9n7xsJPydq6P9OkrZcrqW/u1FNwjLYIxZ+Pvbm/MWiD18Vbju8yemTe6sictZQ2EUiobCLREJhF4mEwi4SCYVdJBIKu0gkfr/G2b3xamftdAAwf9izrI4u88fJv/Cov739iqn+nPRvH74uWBtMmDMOfzgZe08mrK/ujKMD/vrpAyP+WHUO/rkRifPhLROsTarx132fmvXnq3ef9reyTr798PkNB3PhfgPAUEv4uW4ZZ/tu91YBkFxNspfk9jHXPUZyP8mt+Y/bkm5HRNI1kZfxTwNYPM71T5jZvPzH+tJ2S0RKLTHsZrYJwJEK9EVEyqiYN+geJPlG/mV+S+ibSK4g2Umycwj+/3ciUj6Fhv1JAJcAmAegG8B3Qt9oZivNrMPMOmrhvyEjIuVTUNjNrMfMcmY2AuApAPNL2y0RKbWCwk5y7PrDdwDYHvpeEakOiePsJNcCuAlAG8kuAN8CcBPJeQAMwB4AD5SxjyWRnXGBW+/+81lu/ehV4bHNLy/8hdv2r1r9cfJVx85364/0zHPr3phu0j7h/QnrvifNyy5G0lz5wYQ55Un2D4bHwltq/XF0b4weAAZH/OgcH/Yf12Zn//dzavx5/jztHKOdefKJYTezpeNcvSqpnYhUF50uKxIJhV0kEgq7SCQUdpFIKOwikaiqKa4Dd1zv1md9/e1gbVGrP9S/oPFlt/6zE/6Sy5fU9QZr+4bOddt+8YMFbt1bVhgAJteeKrh9f84/a/Gien/aw5Ssf99JQ0x7ToWnyE7K+NNA6xOWmu7JhbdkBoBsjbddtD+09s6APxyapT+lujHjDyt6939RttltO31zuHbIWYVaR3aRSCjsIpFQ2EUiobCLREJhF4mEwi4SCYVdJBIVHWdnXR2yMy4K1u/+G3/dSm86Zmf/HLdtUj1pyuLuzHnB2vHhRrftp5v3u/X9g8FVvSak1hnzTdqaOGm8OUkxt39w0B8nHzH/WLR/YKpbb64NTyO9seU9t23SGP/RYX+r6va6D916a6Y/WOseDtcAoGX9zmAtezx8XoSO7CKRUNhFIqGwi0RCYReJhMIuEgmFXSQSCrtIJCo6zn5qei3eeji8pPM9mf912+8+GR7rnlbX57bNJYzZJo037zsZHgtvb/CXa05aEnlG/VG3njTePDBSF6ydSrjvniF/rPtkzm9/bq0zgRpAg7NctLfUM5A8l/6WFn8Ng5saDwRr/3OyPVgDgJcG/PUNdh0PPxcB4Bf9l7n1nLMGwbOT/ecyPuwKlszZulxHdpFIKOwikVDYRSKhsItEQmEXiYTCLhIJhV0kEpVdN94Ab5rw7NpDbvOe+vD85WM5f055W9afI5yDv3b7hXXh9dWLnTN+dLjJrw/5c6e9cfxit0U+t85/3JJ+ttaa8Dj8n56zzW07t/Y3bv2Bd+5x63/7woxgLfc5/9wG/9kADA37P3cm4291PbUxfA7BZVN73Lbh3RN8iUd2kjNJvkRyJ8kdJL+Sv76V5AaSu/KXxa3AICJlNZGX8cMAvmpmlwP4DIAvkbwCwKMANprZXAAb81+LSJVKDLuZdZvZ6/nP+wDsBDADwBIAa/LftgbA7eXqpIgU7xO9QUdyNoBrAGwGMN3MuoHRPwgApgXarCDZSbIzd8I/j1pEymfCYSfZDOAnAB42M3/mxxhmttLMOsysI9PkvxElIuUzobCTrMVo0J81s5/mr+4h2Z6vtwMIb3MqIqlLHHojSQCrAOw0s++OKa0DsAzA4/nLF5Juq77rBC752ivB+r1tX3TbP/SHG4O1hc1vuW13Dfpb8ML8h2LfYHhb5qRtkZOmgSYtY+1tPTxaDy+ZfGLY79tIwiBT0pLK1zbtceunnaG5r/3gfrftRY/9n1uvw163Ps2pN93lT1F9+9C4/5X+Vk2NP9w6OOj/Tk9mw/Wkqb1AYct/T2ScfQGAewFsI7k1f903MBryH5FcDmAfgDsL6oGIVERi2M3sZYTPMbi5tN0RkXLR6bIikVDYRSKhsItEQmEXiYTCLhIJmvnjhaU0ha12PQt/A5/14THj9//6WrftA0tedOufa37TrV9VF94uuithi93dw81u/cOcP4X14LC/5HKTM85+XsY/2XHRJH8KbNL2wQvXft2tX/zIr9x6Wr65e6tb33ZqpltPmtp7fvaYW99yYnawdssUf4nsJ668Llh75dR6HBv5zbijZzqyi0RCYReJhMIuEgmFXSQSCrtIJBR2kUgo7CKRqK5x9pqEeboj4e1oy+3E568P1g5d4//NzF7uj3Vfd8EHbv3SpsLXBUlahvo/N4R/LgCY82iK4+RlfD4cfPhGt54d8HOROe3ffl2/vwZB/ZHwOgHZX27xb9yx2TbiuB3ROLtIzBR2kUgo7CKRUNhFIqGwi0RCYReJhMIuEonqGmcXkaJonF1EFHaRWCjsIpFQ2EUiobCLREJhF4mEwi4SicSwk5xJ8iWSO0nuIPmV/PWPkdxPcmv+47byd1dECjWR/dmHAXzVzF4nORnAFpIb8rUnzOwfytc9ESmViezP3g2gO/95H8mdAGaUu2MiUlqf6H92krMBXANgc/6qB0m+QXI1yZZAmxUkO0l2DiG8TZGIlNeEw06yGcBPADxsZscBPAngEgDzMHrk/8547cxspZl1mFlHLcJ7tYlIeU0o7CRrMRr0Z83spwBgZj1mljOzEQBPAZhfvm6KSLEm8m48AawCsNPMvjvm+vYx33YHAH/rSRFJ1UTejV8A4F4A20ie2ef2GwCWkpwHwADsAfBAWXooIiUxkXfjXwYw3vzY9aXvjoiUi86gE4mEwi4SCYVdJBIKu0gkFHaRSCjsIpFQ2EUiobCLREJhF4mEwi4SCYVdJBIKu0gkFHaRSCjsIpGo6JbNJA8B2DvmqjYAhyvWgU+mWvtWrf0C1LdClbJvs8zsvPEKFQ37x+6c7DSzjtQ64KjWvlVrvwD1rVCV6ptexotEQmEXiUTaYV+Z8v17qrVv1dovQH0rVEX6lur/7CJSOWkf2UWkQhR2kUikEnaSi0m+TfJdko+m0YcQkntIbstvQ92Zcl9Wk+wluX3Mda0kN5Dclb8cd4+9lPpWFdt4O9uMp/rYpb39ecX/ZyeZAfAOgFsAdAF4DcBSM3uzoh0JILkHQIeZpX4CBsmFAPoBPGNmV+av+zsAR8zs8fwfyhYze6RK+vYYgP60t/HO71bUPnabcQC3A/hLpPjYOf26CxV43NI4ss8H8K6Z7Taz0wCeA7AkhX5UPTPbBODIR65eAmBN/vM1GH2yVFygb1XBzLrN7PX8530Azmwznupj5/SrItII+wwAH4z5ugvVtd+7Afg5yS0kV6TdmXFMN7NuYPTJA2Bayv35qMRtvCvpI9uMV81jV8j258VKI+zjbSVVTeN/C8zsWgC3AvhS/uWqTMyEtvGulHG2Ga8KhW5/Xqw0wt4FYOaYry8EcCCFfozLzA7kL3sBPI/q24q658wOuvnL3pT781vVtI33eNuMowoeuzS3P08j7K8BmEtyDsk6AHcDWJdCPz6GZFP+jROQbAKwCNW3FfU6AMvyny8D8EKKffkd1bKNd2ibcaT82KW+/bmZVfwDwG0YfUf+PQDfTKMPgX5dDODX+Y8dafcNwFqMvqwbwugrouUAzgWwEcCu/GVrFfXt3wFsA/AGRoPVnlLfPovRfw3fALA1/3Fb2o+d06+KPG46XVYkEjqDTiQSCrtIJBR2kUgo7CKRUNhFIqGwi0RCYReJxP8DoKuFf7a/1F0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "**Normalizing the X train and X test data by dividing by the max value of the image arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reshaping the X arrays to include a 4 dimension of the single channel.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(60000, 28, 28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test.reshape(10000, 28, 28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting the y_train and y_test values to be one-hot encoded for categorical analysis by Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_train=to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat_train[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "**Using Keras to create a model consisting of at least the following layers:**\n",
    "\n",
    "* 2D Convolutional Layer, filters=32 and kernel_size=(4,4)\n",
    "* Pooling Layer where pool_size = (2,2)\n",
    "\n",
    "* Flatten Layer\n",
    "* Dense Layer (128 Neurons, but feel free to play around with this value), RELU activation\n",
    "\n",
    "* Final Dense Layer of 10 Neurons with a softmax activation\n",
    "\n",
    "**Then compiling the model with these parameters: loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "# Convulutional layer\n",
    "model.add(Conv2D(filters=32, kernel_size=(4,4), input_shape=(28,28,1), activation='relu',))\n",
    "# Pooling layer\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# Flatten image from 28*28 to764 before final layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# 128 Neron in Dense hidden layer \n",
    "model.add(Dense(128, activation ='relu'))\n",
    "\n",
    "\n",
    "# The last layer is the classifier with possible 10 outputs\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "             optimizer='rmsprop', \n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 591,786\n",
      "Trainable params: 591,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "**Train/Fitting the model to the x_train set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 14s 232us/sample - loss: 0.4045 - accuracy: 0.8542\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 13s 225us/sample - loss: 0.2774 - accuracy: 0.9008\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 13s 223us/sample - loss: 0.2399 - accuracy: 0.9142\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 13s 223us/sample - loss: 0.2147 - accuracy: 0.9233\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 13s 224us/sample - loss: 0.1968 - accuracy: 0.9294\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 14s 225us/sample - loss: 0.1828 - accuracy: 0.9353\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 13s 223us/sample - loss: 0.1708 - accuracy: 0.9402\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 13s 222us/sample - loss: 0.1604 - accuracy: 0.9440\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 13s 222us/sample - loss: 0.1536 - accuracy: 0.9462\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 13s 222us/sample - loss: 0.1455 - accuracy: 0.9493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18379a919c8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_cat_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "**Showing the accuracy,precision,recall,f1-score the model achieved on the x_test data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 56us/sample - loss: 0.3316 - accuracy: 0.9072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3316142331302166, 0.9072]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85      1000\n",
      "           1       0.98      0.98      0.98      1000\n",
      "           2       0.84      0.86      0.85      1000\n",
      "           3       0.93      0.92      0.92      1000\n",
      "           4       0.85      0.85      0.85      1000\n",
      "           5       0.98      0.97      0.98      1000\n",
      "           6       0.82      0.63      0.71      1000\n",
      "           7       0.94      0.98      0.96      1000\n",
      "           8       0.97      0.98      0.98      1000\n",
      "           9       0.98      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
